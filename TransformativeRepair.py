import json
import logging
import os
import random
import threading
import time
import networkx as nx
from pyvis.network import Network
from SmartContract import SmartContract
from PromptEngine import PromptEngine
from networkx.readwrite import json_graph
import multiprocessing
from typing import List
from pathlib import Path
import queue

class TransformativeRepair:
    
    def __init__(self, experiment_settings:dict, llm_settings:dict) -> None:
        self.experiment_settings = experiment_settings
        self.llm_settings = llm_settings

        self.experiments_dir:str = f'experiment_results/{experiment_settings["experiment_name"]}_{experiment_settings["llm_model"]}'
        self.contracts_dir:str = experiment_settings["vulnerable_contracts_directory"]
        self.target_vulnerabilities:List[str] = experiment_settings["target_vulnerabilities"]
        self.patch_examples_dir:str = experiment_settings["patch_examples_directory"]
        self.smartbugs_tools:List[str] = experiment_settings["smartbugs_tools"]
        
        self.prompt_style:str = experiment_settings["prompt_style"]
        self.llm_model:str = experiment_settings["llm_model"]
        self.llm_settings:dict = llm_settings

        self.smartbugs_sc_queue = queue.Queue()
        self.repair_sc_queue = queue.Queue()

    def show_prompt_styles(self, sc_path:str):
        """
        Displays example prompts generated by the PromptEngine for a given Solidity smart contract.

        This function takes a file path to a Solidity smart contract as a parameter, creates an instance of the SmartContract class with the file path, sets its vulnerabilities attribute to a dictionary of detected vulnerabilities, and then creates a PromptEngine instance with the SmartContract instance as a parameter.

        The function then generates and displays three types of prompts using the PromptEngine's generate_prompt() method, each identified by a string parameter: "A_basic", "B_vulnerability_context", and "C_vulnerability_examples". The generated prompts are printed to the console.

        Note: Vulnerability detection tools are not used in this demo function.

        Args:
        - sc_path (str): a string representing the file path to the Solidity smart contract to be analyzed

        """
        sc = SmartContract(sc_path)
        sc.vulnerabilities = {'oyente': ['reentrancy', 'reentrancy']}

        pe = PromptEngine(sc)
        print(f'A_basic\n\n{pe.generate_prompt("A_basic")}\n\n')
        print(f'B_vulnerability_context\n\n{pe.generate_prompt("B_vulnerability_context")}\n\n')
        print(f'C_vulnerability_examples\n\n{pe.generate_prompt("C_vulnerability_examples")}\n\n')
    
    # Visualize
    def visualize_graph_pyvis(self, G:nx.DiGraph, results_path:str):
        nt = Network('800', '100%', directed=True)
        nt.from_nx(G)
        # nt.show_buttons(filter_=['physics'])
        nt.set_options('''{
        "physics": {
            "forceAtlas2Based": {
            "theta": 0.1,
            "gravitationalConstant": -104,
            "springLength": 0,
            "springConstant": 0.5,
            "damping": 1,
            "avoidOverlap": 1
            },
            "maxVelocity": 85,
            "minVelocity": 10,
            "solver": "forceAtlas2Based",
            "timestep": 0.1
        },
        "layout":{
            "randomSeed":2
            }
        }''')
        
        os.makedirs(os.path.dirname(f'{results_path}.html'), exist_ok=True)
        nt.write_html(f'{results_path}.html')
        
        # Save to Json
        data = json_graph.node_link_data(G)
        with open(f'{results_path}.json', 'w') as outfile:
            json.dump(data, outfile)

    @staticmethod
    def create_repair_results_network(sc_path, experiment_settings:dict, llm_settings:dict, smartbugs_sc_queue:queue.Queue) -> nx.DiGraph:
        '''
        Finds vulnerabilities in a smart contract and attempts to repair it using Codex. Then, creates a network of the original smart contract and its repaired versions, showing the repaired vulnerabilities, if any.

        :param sc_path: The file path of the smart contract to repair.
        :type sc_path: str
        :param prompt_style: The prompt style to use for the Codex API, defaults to 'C_vulnerability_examples'.
        :type prompt_style: str
        :param vulnerability_limitations: A list of vulnerability limitations to consider when finding and repairing vulnerabilities, defaults to an empty list.
        :type vulnerability_limitations: list
        :param temperature: A temperature value to use for the Codex API, defaults to 0.8.
        :type temperature: float
        :param top_p: A top-p value to use for the Codex API, defaults to 0.95.
        :type top_p: float
        :param n_repairs: The number of repairs to attempt using the Codex API, defaults to 1.
        :type n_repairs: int
        :return: Graph.
        :rtype: nx.DiGraph
        '''
        model_name = experiment_settings["llm_model"]

        #### Step 1: Initialize SC
        sc = SmartContract(sc_path)

        #### Step2: Specify the results directory path
        sc_results_dir = Path(os.path.join("experiment_results",
            f'{experiment_settings["experiment_name"]}_{model_name}',
            sc.name))
        
        #### Step 3: Find Vulnerabilities
        sc.run_smartbugs(experiment_settings, sc_results_dir)

        #### Step 4: Create Prompt Engine and generate prompt
        pe = PromptEngine(sc)
        prompt = pe.generate_prompt(experiment_settings)
        # Save prompt
        with open(os.path.join(sc_results_dir, "prompt.txt"), 'w') as file:
            file.write(prompt)


        #### Step 5: Repair smart contract
        if model_name == "gpt-3.5-turbo":
            pe.get_codex_repaired_sc(experiment_settings, llm_settings[model_name], sc, prompt)
        else:
            raise KeyError(f'model_name={model_name} not found!')
        
        smartbugs_sc_queue.put((sc.path, False))


        # Path(os.path.join(f'experiment_results/{experiment_settings["experiment_name"]}_{experiment_settings["llm_model"]}',
        #                   sc_name)).mkdir(parents=True, exist_ok=True)

        


        # Path(experiments_dir).mkdir(parents=True, exist_ok=True)
        # sc_path = 'experiments/sc_to_repair/reentrance.sol'
        # sc_directory = 'experiments/sc_to_repair'
        
        # target_vulnerabilities = experiment_settings["target_vulnerabilities"]
        # prompt_style = experiment_settings["prompt_style"]        

        # start_sc.find_vulnerabilities(target_vulnerabilities)




        # pe = PromptEngine(start_sc)

        
        # repaired_contracts = pe.get_codex_repaired_sc(prompt_style, 0.8, 0.95, 1)
        # repaired_contracts = pe.get_codex_repaired_sc(self.prompt_style, temperature, top_p, n_repairs)

        # G = nx.DiGraph()
        # # Create Network
        # # Add START node
        # G.add_node(start_sc.filename, 
        #             # sc_data=start_sc, 
        #             group=1, 
        #             size=30)
        # for repaired_sc in repaired_contracts:
        #     repaired_sc.find_vulnerabilities(self.target_vulnerabilities)
        #     repaired_vulnerabilities = start_sc.get_repaired_vulnerabilities(repaired_sc)
            
        #     G.add_node(repaired_sc.filename, 
        #         # sc_data=repaired_sc, 
        #         group = random.randint(4, 24))

        #     color = 'green'
        #     dashes = False
        #     for tool in repaired_vulnerabilities:
        #         if 'error' in tool:
        #             color = 'red'
        #             dashes = True
        #         elif not tool:
        #             color = 'red'
        #             dashes = False
            
        #     G.add_edge(start_sc.filename, repaired_sc.filename, 
        #         color = color,
        #         dashes = dashes,
        #         weight=0.0,
        #         title=f'Equal={start_sc.hash == repaired_sc.hash} RV={json.dumps(repaired_vulnerabilities)}',
        #         equal= f'Equal={start_sc.hash == repaired_sc.hash}',
        #         capacity=0,
        #         length=0,
        #         alpha=0.9)
        # return G
 
    def find_vulnerabilities_and_repair_sc_in_directory(self):
        
        sc_paths = [os.path.join(self.contracts_dir, sc_path) for sc_path in os.listdir(self.contracts_dir) 
                    if os.path.isfile(os.path.join(self.contracts_dir, sc_path))
                    and os.path.splitext(os.path.basename(sc_path))[1] == ".sol"]
        
        TransformativeRepair.create_repair_results_network(sc_paths[0], self.experiment_settings, self.llm_settings)
        
        # with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:
        #     subgraphs = []
        #     for sc_path in sc_paths:
        #         subgraphs.append(pool.apply_async(TransformativeRepair.create_repair_results_network, args=(sc_path, self.experiment_settings, self.llm_settings)))
        #     pool.close()
        #     pool.join()
        
        #     results = [subgraph.get() for subgraph in subgraphs]

        # Merge the sub-graphs into a single large graph
        G = nx.compose_all(results)

        return G
    
    @staticmethod
    def find_vulnerabilities(experiment_settings:dict, sc_path:str, sc_results_dir:str, do_repair_sc:bool, repair_sc_queue:queue.Queue) -> None:

        try:
            #### Step 1: Initialize SC
            sc = SmartContract(experiment_settings, sc_path, sc_results_dir)
            
            #### Step 3: Create results directory
            if sc.results_dir.exists():
                return # vulnerabilities already found TODO: check results file      
            sc.results_dir.mkdir(parents=True, exist_ok=True)

            #### Step 4: Find Vulnerabilities
            sc.run_smartbugs()

            #### Step 5: Enqueue to repair queue
            if do_repair_sc:
                repair_sc_queue.put(sc.path, sc_results_dir)
        except Exception as e:
            logging.critical(f'An exception occurred when finding vulnerabilities for contract={sc_path}: {str(e)}', exc_info=True)            


    @staticmethod
    def consumer_of_vulnerabilities_queue(experiment_setting:dict, smartbugs_sc_queue:queue.Queue, repair_sc_queue:queue.Queue) -> None:
        sleeps: 0
        while True:
            try:
                sleeps = 0
                sc_path, sc_results_dir, do_repair_sc = smartbugs_sc_queue.get(block=False)
                TransformativeRepair.find_vulnerabilities(experiment_setting, sc_path, sc_results_dir, do_repair_sc, repair_sc_queue)
            except queue.Empty:
                # The queue is empty, so sleep for a short time before trying again
                if sleeps == 10:
                    return
                time.sleep(10)
                sleeps += 1


    @staticmethod
    def repair_sc(experiment_settings:dict, llm_settings:dict, sc_path:str, sc_results_dir:str, smartbugs_sc_queue:queue.Queue):
        
        #### Step 1: Initialize SC
        sc = SmartContract(experiment_settings, sc_path, sc_results_dir)
        
        #### Step 2: Create Prompt Engine and generate prompt
        pe = PromptEngine(sc)
        prompt = pe.generate_prompt(experiment_settings)

        #### Step 3: Save prompt
        with open(os.path.join(sc.results_dir, "prompt.txt"), 'w') as file:
            file.write(prompt)
        
        #### Step 4: Repair smart contract
        model_name = experiment_settings["llm_model"]
        candidate_patches_paths = []
        if model_name == "gpt-3.5-turbo":
            candidate_patches_paths = pe.get_codex_repaired_sc(experiment_settings, llm_settings[model_name], sc, prompt)
        else:
            raise KeyError(f'model_name={model_name} not found!')
        
        #### Step 5: Add to find vulnerabilities queue
        for candidate_patch in candidate_patches_paths:
            smartbugs_sc_queue.put(candidate_patch, os.path.join(sc.results_dir, "candidate_patches"), False)


    @staticmethod
    def consumer_of_repair_queue(experiment_setting:dict, llm_settings:dict, smartbugs_sc_queue:queue.Queue, repair_sc_queue:queue.Queue):
        sleeps: 0
        while True:
            try:
                sleeps = 0
                sc_path, sc_results_dir = repair_sc_queue.get(block=False)
                TransformativeRepair.repair_sc(experiment_setting, llm_settings, sc_path, sc_results_dir, smartbugs_sc_queue)
            except queue.Empty:
                # The queue is empty, so sleep for a short time before trying again
                if sleeps == 10:
                    return
                time.sleep(10)
                sleeps += 1
    
    def start(self):
        
        #### Step 1: Add all vulnerable sc to smartbugs_sc_queue
        results_dir = os.path.join("experiment_results",
                f'{self.experiment_settings["experiment_name"]}_{self.experiment_settings["llm_model"]}')
        for sc_path in os.listdir(self.contracts_dir):
            if os.path.isfile(os.path.join(self.contracts_dir, sc_path)) and os.path.splitext(os.path.basename(sc_path))[1] == ".sol":
                self.smartbugs_sc_queue.put((os.path.join(self.contracts_dir, sc_path), results_dir, True))
        # sc_paths = [self.queue_find_vulnerabilities.put(os.path.join(self.contracts_dir, sc_path)) for sc_path in os.listdir(self.contracts_dir) 
        #             if os.path.isfile(os.path.join(self.contracts_dir, sc_path))
        #             and os.path.splitext(os.path.basename(sc_path))[1] == ".sol"]
        
        #### Step 2: Consume smartbugs_queue
        for i in range(self.experiment_settings["n_smartbugs_threads"]):
            smartbugs_thread = threading.Thread(target=TransformativeRepair.consumer_of_vulnerabilities_queue, args=(self.experiment_settings, self.smartbugs_sc_queue, self.repair_sc_queue))
            smartbugs_thread.start()

        #### Step 2: Consume smart repair_sc_queue
        for i in range(self.experiment_settings["n_repair_threads"]):
            repair_thread = threading.Thread(target=TransformativeRepair.consumer_of_repair_queue, args=(self.experiment_settings, self.llm_settings, self.smartbugs_sc_queue, self.repair_sc_queue))
            repair_thread.start()
            repair_thread.join()

        # smartbugs_thread = threading.Thread(target=TransformativeRepair.start_smartbugs_analyzers, args=(self.experiment_settings, sc_paths))
        # codex_thread = threading.Thread(target=launch_codex_service, args=(contracts_dir, results_dir))
        # smartbugs_thread.start()
        # codex_thread.start()

        # TransformativeRepair.create_repair_results_network(sc_paths[0], self.experiment_settings, self.llm_settings)
        
        # with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:
        #     subgraphs = []
        #     for sc_path in sc_paths:
        #         subgraphs.append(pool.apply_async(TransformativeRepair.create_repair_results_network, args=(sc_path, self.experiment_settings, self.llm_settings)))
        #     pool.close()
        #     pool.join()
        
        #     results = [subgraph.get() for subgraph in subgraphs]

        # Merge the sub-graphs into a single large graph
        # G = nx.compose_all(results)

        #return

        